---
title: "Journal (reproducible report)"
author: "Rudan Deng"
date: "2020-11-06"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: true
    toc_depth: 3
    #code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```

**IMPORTANT:** You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.

This is an `.Rmd` file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a \# in front of your text, it will create a top level-header.

# Intro to the Tidyverse

Last compiled: `r Sys.Date()`


## Sales by location

Analyze the sales by state:
Which state has the highest revenue?
```{r plot, fig.width=10, fig.height=7}
# We want to analyze the total sales by state (= 1st location). 
# To do it, we have to separate the column location in city, state
# and add the total price (sales price * quantity) to the data.
# 0.0 Load libraries ----
library(tidyverse)
# Excel Files
library(readxl)
# 0.1 Importing Files ----
# A good convention is to use the file name and suffix it with tbl for the data structure tibble
bikes_tbl      <- read_excel(path = "/Users/rudandeng/Documents/05-ICS_Win2020/fund_DS_ws20/DS_101/00_data/01_bike_sales/01_raw_data/bikes.xlsx")
orderlines_tbl <- read_excel("/Users/rudandeng/Documents/05-ICS_Win2020/fund_DS_ws20/DS_101/00_data/01_bike_sales/01_raw_data/orderlines.xlsx")

bikeshops_tbl  <- read_excel("/Users/rudandeng/Documents/05-ICS_Win2020/fund_DS_ws20/DS_101/00_data/01_bike_sales/01_raw_data/bikeshops.xlsx")

# Chaining commands with the pipe and assigning it to order_items_joined_tbl
bike_orderlines_joined_tbl <- orderlines_tbl %>%
        left_join(bikes_tbl, by = c("product.id" = "bike.id")) %>%
        left_join(bikeshops_tbl, by = c("customer.id" = "bikeshop.id"))

# 1.0 Wrangling Data ----
# All actions are chained with the pipe already. 
# You can perform each step separately and use glimpse() or View() to validate your code. 
# Store the result in a variable at the end of the steps.
bike_orderlines_wrangled_tbl <- bike_orderlines_joined_tbl %>%
  # 1.1 Separate location name
  separate(col    = location,
           into   = c("city", "state"),
           sep    = ", ") %>%
  # 1.2 Add the total price (price * quantity) 
  # Add a column to a tibble that uses a formula-style calculation of other columns
  mutate(total.price = price * quantity) %>%
  # 1.3 Optional: Reorganize. Using select to grab or remove unnecessary columns
  # 1.3.1 by exact column name
  select(-...1, -gender) %>%
  
  # 1.3.2 by a pattern
  # You can use the select_helpers to define patterns. 
  # Type ?ends_with and click on Select helpers in the documentation
  select(-ends_with(".id")) %>%
  # 1.3.3 Actually we need the column "order.id". Let's bind it back to the data
  bind_cols(bike_orderlines_joined_tbl %>% select(order.id)) %>%
  
  # 1.3.4 You can reorder the data by selecting the columns in your desired order.
  # You can use select_helpers like contains() or everything()
  select(order.id, contains("order"), contains("model"), contains("category"),
         price, quantity, total.price,
         everything()) %>%
  
  # 1.3.5 Rename columns because we actually wanted underscores instead of the dots
  # (one at the time vs. multiple at once)
  rename(bikeshop = name) %>%
  set_names(names(.) %>% str_replace_all("\\.", "_"))
# 2.0 Business Insights ----
# 2.1 Sales by State ----
# Step 1 - Manipulate
sales_by_state_tbl <- bike_orderlines_wrangled_tbl %>%
  
  # Select columns
  select(state, total_price) %>%
  
  # Grouping by state and summarizing sales
  group_by(state)  %>%
  summarize(sales = sum(total_price)) %>%
  
  # Optional: Add a column that turns the numbers into a currency format 
  # (makes it in the plot optically more appealing)
  # mutate(sales_text = scales::dollar(sales)) <- Works for dollar values
  mutate(sales_text = scales::dollar(sales, big.mark = ".", 
                                     decimal.mark = ",",
                                     prefix = " ", 
                                     suffix = " €"))

# 3.1 Sales by State ----

# Step 2 - Visualize
sales_by_state_tbl %>%
  
  # Setup canvas with the columns state (x-axis) and sales (y-axis)
  ggplot(aes(x = state, y = sales)) +
  
  # Geometries
  geom_col(fill = "#2DC6D6") + # Use geom_col for a bar plot
  geom_label(aes(label = sales_text)) + # Adding sales to the bars
  geom_smooth(method = "lm", se = FALSE) + # Adding a trendline
  
  # Formatting
  # scale_y_continuous(labels = scales::dollar) + # Change the y-axis. 
  # Again, we have to adjust it for euro values
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".", 
                                                    decimal.mark = ",", 
                                                    prefix = "", 
                                                    suffix = " €")) +
  labs(
    title    = "Revenue by State",
    subtitle = "",
    x = "State", # Override defaults for x and y
    y = "Revenue"
  ) +
  # to rotate x-axis labels
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Sales by location and year

Analyze the sales by location and year (facet_wrap).
```{r plot_1, fig.width=13, fig.height=7}
# 1.1 Sales by Year ----
library(lubridate)
# Step 1 - Manipulate
sales_by_year_tbl <- bike_orderlines_wrangled_tbl %>%
 
  # Select columns
  select(order_date, total_price) %>%

  # Add year column
  mutate(year = year(order_date)) %>%
 
  # Grouping by year and summarizing sales
  group_by(year) %>% 
  summarize(sales = sum(total_price)) %>%
 
  mutate(sales_text = scales::dollar(sales, big.mark = ".", 
                                     decimal.mark = ",", 
                                     prefix = "", 
                                     suffix = " €"))

# Step 2 - Visualize
  sales_by_year_tbl %>%
  
  # Setup canvas with the columns year (x-axis) and sales (y-axis)
  ggplot(aes(x = year, y = sales)) +
  
  # Geometries
  geom_col(fill = "#2DC6D6") + # Use geom_col for a bar plot
  geom_label(aes(label = sales_text)) + # Adding labels to the bars
  geom_smooth(method = "lm", se = FALSE) + # Adding a trendline

  # Formatting
  # scale_y_continuous(labels = scales::dollar) + # Change the y-axis. 
  # Again, we have to adjust it for euro values
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".", 
                                                    decimal.mark = ",", 
                                                    prefix = "", 
                                                    suffix = " €")) +
  labs(
    title    = "Revenue by year",
    subtitle = "Upward Trend",
    x = "", # Override defaults for x and y
    y = "Revenue"
  )
  
  # 1.2 Sales by Year and Location ----
# Step 1 - Manipulate
sales_by_year_state_tbl <- bike_orderlines_wrangled_tbl %>%
 
  # Select columns and add a year
  select(order_date, total_price, state) %>%
  mutate(year = year(order_date)) %>%

  # Group by and summarize year and state
  group_by(year, state) %>%
  summarise(sales = sum(total_price)) %>%
  ungroup() %>%

  # Format $ Text
  mutate(sales_text = scales::dollar(sales, big.mark = ".", 
                                     decimal.mark = ",", 
                                     prefix = "", 
                                     suffix = " €"))
# Step 2 - Visualize
sales_by_year_state_tbl %>%

  # Set up x, y, fill
  ggplot(aes(x = year, y = sales, fill = state)) +

  # Geometries
  geom_col() + # Run up to here to get a stacked bar plot
  geom_smooth(method = "lm", se = FALSE) + # Adding a trendline

  # Facet
  facet_wrap(~ state) +

  # Formatting
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".", 
                                                    decimal.mark = ",", 
                                                    prefix = "", 
                                                    suffix = " €")) +
  labs(
    title = "Revenue by year and location",
    subtitle = "",
    fill = "States" # Changes the legend name
  )

```

# Data Acquisition

## Get Data via API
Get some data via an API. 
Working with Open Notify API, which opens up data on various NASA projects, below presents the peoples who are now in the space.
```{r table_1}
library(httr)
library(jsonlite)

resp <- GET("http://api.open-notify.org/astros.json")
resp
rawToChar(resp$content)
data = fromJSON(rawToChar(resp$content))
names(data)
data$people
```
## MTB Category Price List of Rosebikes

```{r table_2}
# WEBSCRAPING ----

# 1.0 LIBRARIES ----

library(tidyverse) # Main Package - Loads dplyr, purrr, etc.
library(rvest)     # HTML Hacking & Web Scraping
library(xopen)     # Quickly opening URLs
library(jsonlite)  # converts JSON files to R objects
library(glue)      # concatenate strings
library(stringi)   # character string/text processing

# 1.1 COLLECT PRODUCT PRICE OF MTB CATEGORY ----

url_mtb          <- "https://www.rosebikes.de/fahrräder/mtb"

# Read in the HTML for the MTB category
html_home         <- read_html(url_mtb)

bike_family_tbl <- html_home %>%
  
# Get the nodes for the MTB category
  html_nodes(css = ".catalog-category-bikes__button") %>%
  html_attr("href") %>%
  enframe(name = "position", value = "product_url") %>%
  mutate(
    url = glue("https://www.rosebikes.de{product_url}"))%>%
  distinct(url)

# get the bike name  
  get_bike_data <- function(a) {
  html_bike_mtb  <- read_html(a)
  
  bike_url_tbl        <- html_bike_mtb %>%
    html_nodes(css = ".catalog-category-model__title") %>%
    html_text() %>%   
    stringr::str_replace_all(pattern = "\\\n", replacement = "")%>%
    enframe(name = "position", value = "bike_name")
}

bike_category_url_vec <- bike_family_tbl$url

bike_data_lst <- map(bike_category_url_vec, get_bike_data)
bike_data_tbl <- bind_rows(bike_data_lst) 

# get the bike price
  
  get_bike_price <- function(b) {
  html_bike_mtb  <- read_html(b)
  
  bike_url_tbl        <- html_bike_mtb %>%
    html_nodes(css = ".catalog-category-model__price-current-value") %>%
  html_text() %>%   
  stringr::str_replace_all(pattern = "\\\n", replacement = "")%>%
    enframe(name = "position", value = "bike_price")
}

bike_category_url_vec <- bike_family_tbl$url

bike_price_lst <- map(bike_category_url_vec, get_bike_price)
bike_price_tbl <- bind_rows(bike_price_lst) 

bike_mtb_tbl <- left_join(bike_data_tbl, bike_price_tbl)
bike_mtb_tbl

```


# Data Wrangling

```{r calculation, eval=FALSE}
#1. Libraries

# Tidyverse
library(tidyverse)
library(vroom)

# Data Table
library(data.table)

# Counter
library(tictoc)

#2. Import data
# assignee
col_types <- list(
  id = col_character(NULL),
  type = col_character(NULL),
  name_first = col_character(NULL),
  name_last = col_character(NULL),
  organization = col_character(NULL)
)

assignee_tbl <- vroom(
  file       = "/Users/rudandeng/Documents/05-ICS_Win2020/fund_DS_ws20/DS_101/00_data/assignee.tsv", 
  delim      = "\t", 
  col_types  = col_types,
  na         = c("", "NA", "NULL")
)

# patent_assignee
col_types_pat <- list(
  patent_id = col_double(),
  type = col_character(NULL),
  location_id = col_character(NULL)
)

patent_assignee_tbl <- vroom(
  file       = "/Users/rudandeng/Documents/05-ICS_Win2020/fund_DS_ws20/DS_101/00_data/patent_assignee.tsv", 
  delim      = "\t", 
  col_types  = col_types,
  na         = c("", "NA", "NULL")
)


setnames(patent_assignee_tbl, "assignee_id", "id")


# patent
col_patent <- list(
  patent_id = col_character(),
  patent_type = col_character(),
  number = col_character(),
  country = col_character(),
  date = col_date("%Y-%m-%d"),
  abstract = col_character(),
  title = col_character(),
  kind = col_character(),
  num_claims = col_double(),
  filename = col_character(),
  withdrawn = col_double()
)

patent_tbl <- vroom(
  file       = "/Users/rudandeng/Documents/05-ICS_Win2020/fund_DS_ws20/DS_101/00_data/patent.tsv", 
  delim      = "\t", 
  col_names  = names(col_patent),
  col_types  = col_patent,
  na         = c("", "NA", "NULL")
)

# uspc
col_uspc <- list(
  uuid = col_character(),
  patent_id = col_character(),
  mainclass_id = col_character(),
  subclass_id = col_character(),
  sequence= col_double()
)

uspc_tbl <- vroom(
  file       = "/Users/rudandeng/Documents/05-ICS_Win2020/fund_DS_ws20/DS_101/00_data/uspc.tsv", 
  delim      = "\t", 
  col_names  = names(col_uspc),
  col_types  = col_uspc,
  na         = c("", "NA", "NULL")
)


# 3. Convert to data table ----

setDT(assignee_tbl)
setDT(patent_assignee_tbl)
setDT(patent_tbl)
setDT(uspc_tbl)
```

```{r, calculation_1, eval = FALSE}
# 4 DATA WRANGLING ----
# merge the data via the id
tic()
combined_data <- merge(x = patent_assignee_tbl, y = assignee_tbl, 
                       by    = "id", 
                       all.x = TRUE, 
                       all.y = FALSE)
toc()

# 1.Patent Dominance: What US company / corporation has the most patents? List the 10 US companies with the most assigned/granted patents.
result1 <-combined_data %>% 
  select("type","id", "organization") %>%
  filter(type == 2) %>%
  group_by(organization) %>%
  summarise(num_of_patent = n()) %>%
  ungroup() %>%
  arrange(desc(num_of_patent)) %>%
  head(10)

write_rds(result1,"/Users/rudandeng/Documents/05-ICS_Win2020/fund_DS_ws20/outer_ws20-business-data-science-basics---lab-journal-Rudan-Deng/ws20-business-data-science-basics---lab-journal-Rudan-Deng/result1.rds")

# 2.List the top 10 companies with the most new granted patents for 2019.
tic()
combined_data_2 <- merge(x = combined_data, y = patent_tbl, 
                       by    = "patent_id", 
                       all.x = TRUE, 
                       all.y = FALSE)
toc()

result2 <-combined_data_2 %>%
  filter(type ==2) %>%
  filter(year(date)== 2019)%>%
  group_by(organization)%>%
  summarise(patent_num_2019=n())%>%
  ungroup()%>%
  arrange(desc(patent_num_2019))%>%
  head(10)

write_rds(result2,"/Users/rudandeng/Documents/05-ICS_Win2020/fund_DS_ws20/outer_ws20-business-data-science-basics---lab-journal-Rudan-Deng/ws20-business-data-science-basics---lab-journal-Rudan-Deng/result2.rds")

# 3.What are the top 5 USPTO tech main classes?
tic()
combined_data_3 <- merge(x = uspc_tbl, y = combined_data, 
                         by    = "patent_id", 
                         all.x = TRUE, 
                         all.y = FALSE)
toc()
setnames(combined_data_3, "location_id", "id")

result3_1<-combined_data_3 %>%
  select("mainclass_id", "id") %>%
  filter(id %in% c("org_ONzMjdbZXiKfw4L0cXl6", 
                   "org_eAKK85fawH0NS7AdXOig",
                   "org_pCbqlmAg8wlWzoi18ITD",
                   "org_yOSqt2KbCZQB2LRNpEKS",
                   "org_rWEJSmVQtQg24yFJqVRb",
                   "org_EccJQIigrq4WyGinD0b8",
                   "org_g8U335TH48QmGJOIQnNl",
                   "org_WX2Md025ShOVLD08FWsB",
                   "org_f0ZEyISdLqKONLOyVOevn",
                   "org_BWCG5LH9fZoKquGsGsrT")) %>%
  group_by(mainclass_id)%>%
  summarise(num_of_mainclass_id=n())%>%
  ungroup()%>%
  arrange(desc(num_of_mainclass_id))%>%
  head(5)  
  
write_rds(result3_1,"/Users/rudandeng/Documents/05-ICS_Win2020/fund_DS_ws20/outer_ws20-business-data-science-basics---lab-journal-Rudan-Deng/ws20-business-data-science-basics---lab-journal-Rudan-Deng/result3_1.rds")


```

```{r result_1}
# 1.Patent Dominance: What US company / corporation has the most patents? List the 10 US companies with the most assigned/granted patents.
library(readr)
library(data.table)
result_1<-read_rds("/Users/rudandeng/Documents/05-ICS_Win2020/fund_DS_ws20/outer_ws20-business-data-science-basics---lab-journal-Rudan-Deng/ws20-business-data-science-basics---lab-journal-Rudan-Deng/result1.rds")
result_1
```

```{r result_2}
# 2.List the top 10 companies with the most new granted patents for 2019.
library(readr)
library(data.table)
result_2<-read_rds("/Users/rudandeng/Documents/05-ICS_Win2020/fund_DS_ws20/outer_ws20-business-data-science-basics---lab-journal-Rudan-Deng/ws20-business-data-science-basics---lab-journal-Rudan-Deng/result2.rds")
result_2
```

```{r result_3}
# 3.What are the top 5 USPTO tech main classes?
library(readr)
library(data.table)
result_3<-read_rds("/Users/rudandeng/Documents/05-ICS_Win2020/fund_DS_ws20/outer_ws20-business-data-science-basics---lab-journal-Rudan-Deng/ws20-business-data-science-basics---lab-journal-Rudan-Deng/result3_1.rds")
result_3
```

# Data Visualization

## Goal 1: Map the time course of the cumulative Covid-19 cases
```{r plot_3, fig.width=10, fig.height=7}

library(tidyverse)
library(dplyr)
library(lubridate)
library(scales)
library(ggrepel)

covid_data_tbl <- read_csv("https://opendata.ecdc.europa.eu/covid19/casedistribution/csv")

# Data Manipulation
acc_covid_data_tbl <- covid_data_tbl %>%
  
  # Select relevant columns
  select( month, year, dateRep, cases, countriesAndTerritories) %>%
  filter(countriesAndTerritories %in% c("Germany", 
                                        "United_Kingdom",
                                        "France",
                                        "Spain",
                                        "United_States_of_America")) %>%
  filter(year==2020) %>%
  mutate(date=dmy(dateRep))%>%
  group_by(countriesAndTerritories) %>%
  # Sort by this column
  arrange(countriesAndTerritories,date) %>%
  mutate(cum_case_daily = cumsum(cases)) 

tag <- acc_covid_data_tbl%>%
  filter(date=="2020-11-30") %>%
  filter(countriesAndTerritories%in% c("United_States_of_America","France"))%>%
  mutate(cum_case_tag=scales::dollar(cum_case_daily, big.mark = '.',
                                      decimal.mark =',',
                                      prefix = '',
                                      suffix =""))



# Data Visualization

acc_covid_data_tbl %>%
  
  # Canvas
  ggplot(aes(date, cum_case_daily, color = countriesAndTerritories)) +
  geom_line() +
  geom_label_repel(data = tag,
                   aes(label=cum_case_tag,fill=countriesAndTerritories),
                   colour="white",fontface="bold",show.legend=FALSE,
                   hjust = 2
  )+
  scale_y_continuous(labels = scales::unit_format(scale = 1e-6, 
                                                  preix = "",
                                                  suffix = "M"))+
  scale_x_date(breaks = date_breaks("months"),labels = date_format("%B"))+
  xlab('Year 2020') + ylab('Cumulative Cases') +
  theme(legend.position = "bottom",
        panel.background=element_rect(fill="black"),axis.text.x = element_text(angle = 45, hjust = 1))+
  guides(col=guide_legend("Continent/Country"))
```

## Goal2: Visualize the distribution of the mortality rate (deaths / population) with geom_map(). 
```{r plot_4, fig.width=10, fig.height=7}
library(ggplot2)
library(tidyverse)
library(ggrepel)

covid_data_tbl <- read_csv("https://opendata.ecdc.europa.eu/covid19/casedistribution/csv")

world <- map_data("world")


world %>%
    mutate(Country = region) %>%
    group_by(region) %>%
    mutate(Country = case_when(
      Country == 'USA' ~ 'USA',
      Country == "United_Kingdom" ~ "UK",
      Country == 'United_States_of_America' ~ 'USA',
      Country == "Czechia" ~ "Czech Republic",
      TRUE ~ Country
    )) -> world

data_country <- covid_data_tbl %>%   
  select(countriesAndTerritories, dateRep,cases,deaths, popData2019) %>%
  group_by(countriesAndTerritories) %>%
  summarise(pop = mean(popData2019), deaths_sum = sum(deaths))%>%
  ungroup()%>%
  mutate(death_rate = deaths_sum/pop)
              
  

colnames(data_country)[1] <- "Country"

data_country %>%
    mutate(Country = case_when(
      Country == "United_Kingdom" ~ "UK",
      Country == 'United_States_of_America' ~ 'USA',
      Country == "Czechia" ~ "Czech Republic",
      TRUE ~ Country
      )) ->data_country

new_df <- left_join(world, data_country, by = 'Country')


world_map <-    
  ggplot(new_df, aes(map_id = Country)) +
    geom_map(aes(fill=death_rate), map=world, colour="grey",size = 0.1) +
    expand_limits(x = world$long, y = world$lat) + 
    scale_fill_distiller(palette = "Reds",direction= 1, 
                         labels = scales::dollar_format(0.001,scale = 1e2, 
                                          decimal.mark = ".", 
                                          prefix = "",
                                          suffix = "%"),
                         breaks=c(seq(0,0.0014,0.0002))) +
      
labs(
  title = 'Confirmed CVOID-19 deaths relative to the size of the population',
  subtitle = "More than 1.4 Million confirmed COVID-19 deaths worldwide",
  caption = "Date: 06/12/2020",
  x = "",
  y = ""
)+
theme(panel.grid=element_line(color = "grey"),
      panel.background=element_rect(fill="black"),
      panel.border = element_blank(),
      axis.text = element_blank())
world_map
```


















